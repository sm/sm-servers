worker_processes  2;

user {{service_user}} {{service_user}};

error_log {{service_log_path}}/error.log info;
pid       {{service_pid_file}};

events {
  worker_connections  1024;
}

http {
  log_format main '$remote_addr - $remote_user [$time_local] '
                  '$status - "$request" ("$request_filename": $body_bytes_sent bytes) from "$http_referer" '
                  '"$http_user_agent" "$http_x_forwarded_for"';

  access_log {{service_log_path}}/access.log;

  include {{service_config_path}}/conf/mime.types;

  server_names_hash_bucket_size 128;
  client_max_body_size          50M;
  charset                       utf-8;
  default_type                  application/octet-stream;
  sendfile                      on;
  tcp_nopush                    on;

  # Keepalive is good up to to a certain point
  # 2 seconds seems to give the client enough time to request all of the files needed for a
  #  page without having to open multiple connections while still allowing
  #  termination of the connection soon enough to be able to handle many more clients.
  keepalive_timeout 2;

  gzip              on;
  gzip_http_version 1.0;
  gzip_comp_level   8;
  gzip_buffers      16 8k;
  gzip_proxied      any;
  gzip_types        text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript;

  include {{service_config_path}}/servers/*.conf;
}

